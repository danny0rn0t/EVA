# -*- coding: utf-8 -*-
"""CMU-MOSEI_workstation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X-Nu_O7zM0JdPtMLAY98QqW8BxxEJGbW
"""

# !nvidia-smi
# !ls /

"""### Mount Drive"""

# from google.colab import drive
# drive.mount('/content/gdrive')

"""### Install Packages"""

# !pip install transformers

"""### Download Dataset"""

# !file_id=$1
# !file_name=$2

# first stage to get the warning html
# !curl -c /tmp/cookies "https://drive.google.com/uc?export=download&id=1JC5oagD2zYAJtjvQ2xlxRZqi6Qf1_uAd" > ./intermezzo.html

# second stage to extract the download link from html above
# !download_link=$(cat ./intermezzo.html | grep -Po 'uc-download-link" [^>]* href="\K[^"]*' | sed 's/\&amp;/\&/g')
# !curl -L -b /tmp/cookies "https://drive.google.com$download_link" > MOSEI.zip

# import os
# if os.path.exists('MOSEI.zip') == False:
#   !gdown --id 1JC5oagD2zYAJtjvQ2xlxRZqi6Qf1_uAd -O MOSEI.zip
#   !unzip MOSEI.zip 
# if os.path.exists('folds.py') == False:
#   !gdown --id 1WxMCzYMZRLvuCqthU-lYrjW2bIxi5o9c -O folds.py

"""### Data Preprocessing"""

def cmumosei_round(a):
  if a < -2:
    res = -3
  if -2 <= a and a < -1:
    res = -2
  if -1 <= a and a < 0:
    res = -1
  if 0 <= a and a <= 0:
    res = 0
  if 0 < a and a <= 1:
    res = 1
  if 1 < a and a <= 2:
    res = 2
  if a > 2:
    res = 3
  return res + 3 ### right shift 10 to avoid negative labels

"""### Import Packages"""

import os, sys
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import csv
import torchvision.transforms as transforms
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor
from transformers import HubertForSequenceClassification, HubertModel, HubertConfig
from torch.utils.data import Dataset, DataLoader, Subset
from torchvision.datasets import DatasetFolder
from tqdm.auto import tqdm
import librosa
import random, math

from folds import standard_train_fold, standard_valid_fold, standard_test_fold

"""### Fix Random Seeds"""

myseed = 123
def same_seeds(seed):
	  torch.manual_seed(seed)
	  if torch.cuda.is_available():
		    torch.cuda.manual_seed(seed)
		    torch.cuda.manual_seed_all(seed)
	  np.random.seed(seed)
	  torch.backends.cudnn.benchmark = False
	  torch.backends.cudnn.deterministic = True
same_seeds(myseed)

"""### Hyperparameters"""
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--cuda", default=0)
args = parser.parse_args()
config = {
    'device': f'cuda:{args.cuda}',
    'task': 'CMU-MOSEI',
    'num_label': 7,
    'num_epoch': 5,
    'train_batch_size': 8,
    'eval_batch_size': 4,
    'test_batch_size': 4,
    'bert_model': "facebook/hubert-large-ls960-ft",
    'optimizer': 'AdamW',  
    'optim_hp': {
        'lr': 1e-5,
    },
    'loss_function': 'CrossEntropyLoss',
}

"""### Dataset & DataLoader"""

class MOSEIDataset(Dataset):
  def __init__(self, mode):
    self.flag = 0
    self.mode = mode
    if mode == 'train':
      self.fold = standard_train_fold
    elif mode == 'valid':
      self.fold = standard_valid_fold
    elif mode == 'test':
      self.fold = standard_test_fold
    else:
      raise Exception('mode error!')
    # self.labels_path = '/content/Raw_b/Labels/labels.csv'
    # self.datas_path = '/content/Raw_b/Audio/Full/WAV_16000/'
    self.labels_path = '/tmp2/b08902144/miulab/CMU_MOSEI/Raw_b/Labels/labels.csv'
    # self.datas_path = '/tmp2/b08902144/miulab/CMU_MOSEI/Raw_b/Audio/Full/WAV_16000/'
    self.datas_path = '/tmp2/b08902144/miulab/CMU_MOSEI/Raw/Wavs/'
    self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config["bert_model"])
    self.labels = pd.read_csv(self.labels_path)
    # print('preview labels:')
    # for i in range(30):
    #   print(self.labels['sentiment'][i], end=' ')
    # print()
    self.labels = self.labels.loc[self.labels["video_id"].isin(self.fold)].reset_index(drop=True)
    print(f'{mode} data length: {len(self.labels)}')
  def __getitem__(self, index):
    id = self.labels.loc[index]
    speech, _ = librosa.load(self.datas_path + f"{id['video_id']}_{id['clip']}.wav", sr=16000)
    inputs = self.feature_extractor(speech, sampling_rate=16000, padding='max_length', max_length=250000, return_attention_mask=True, return_tensors="pt")
    mask = inputs.attention_mask
    inputs = inputs.input_values
    max_length = 250000
    if self.flag < 30:
      # print(f'geitem: input shape = {inputs.shape}, {speech.shape}')
      print(f"label = {id['sentiment'] + 3}")
      self.flag += 1
    if inputs.shape[1] > max_length:
        r = random.randint(0, inputs.shape[1]-max_length)
        inputs = inputs[0][r:r + max_length].unsqueeze(0)
        mask = mask[0][r:r + max_length].unsqueeze(0)
    return inputs, mask, id['sentiment'] + 3
  def __len__(self):
    return len(self.labels)

train_dataset = MOSEIDataset('train') 
dev_dataset = MOSEIDataset('valid')
test_dataset = MOSEIDataset('test')

trainLoader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True, drop_last=False)
devLoader = DataLoader(dev_dataset, batch_size=config['eval_batch_size'], shuffle=False, drop_last=False)
testLoader = DataLoader(test_dataset, batch_size=config['test_batch_size'], shuffle=False, drop_last=False)

"""### Define Model"""

class Classifier(nn.Module):
  def __init__(self):
    super(Classifier, self).__init__()
    hubertconfig = HubertConfig(num_labels = config['num_label'], use_weighted_layer_sum=True, output_hidden_states=False)
    self.hubert_layers = HubertForSequenceClassification(hubertconfig)
    self.hubert_layers.hubert.from_pretrained(config['bert_model'])
    # print(self.hubert_layers)
    self.fc_layers = nn.Sequential(
        nn.ReLU(),
        nn.Linear(768, 3072),
        nn.ReLU(),
        nn.Linear(3072, config['num_label']),
    )
    self.softmax = nn.Softmax(dim=-1)
    self.flag = 0
  def forward(self, x, mask):
    x = self.hubert_layers(input_values = x, attention_mask = mask).logits
    if self.flag < 0:
      print(f'forward: x.shape = {x.shape}, {x}')
      self.flag += 1
    # x = x[:, 0]
    # print(x.shape)
    # x = self.fc_layers(x)
    # x = self.softmax(x)
    # print(f'after: {x.shape}')
    return x

"""### Training"""
print('Start training...')
device = config['device']
print(f'device = {device}')

model = Classifier().to(device)
# print(model)
# print('=====split=====')
for name, param in model.hubert_layers.hubert.named_parameters():
  print(name)
  param.requires_grad = False                                           
  for i in range(9, 12):
    if f'layers.{i}' in name:
      param.requires_grad = True
      break

criterion = getattr(nn, config['loss_function'])()
optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), **config['optim_hp'])

### debug
flag1 = flag2 = 0

for epoch in range(config['num_epoch']):
  model.train()
  train_loss = []
  train_accs = [] ### match exactly 
  train_acc2 = [] ### partially correct 

  step = 0
  for batch in tqdm(trainLoader):
    step += 1
    inputs, mask, label = batch
    # print(f'before: {inputs.shape}')
    inputs = torch.squeeze(inputs, 1)
    inputs = inputs.to(device)
    mask = mask.to(device)
    # print(f'after: {inputs.shape}')
    logits = model(inputs, mask)
    # print(label.dtype)
    loss = criterion(logits, label.to(device))
    # if flag1 < 5: ### debug
    #   print('flag1 start')
    #   print(logits.argmax(dim=-1))
    #   print(label)
    #   print('flag1 end')
    #   flag1 += 1

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    acc = (logits.argmax(dim=-1) == label.to(device)).float().mean()
    acc2 = (abs(logits.argmax(dim=-1) - label.to(device)) / config['num_label']).float().mean()

    if step % 25 == 0:
      print(f'Loss = {sum(train_loss) / len(train_loss)}; acc = {sum(train_accs) / len(train_accs)}')
    train_loss.append(loss.item())
    train_accs.append(acc.item())
    train_acc2.append(acc2.item())

  train_loss = sum(train_loss) / len(train_loss)
  train_acc = sum(train_accs) / len(train_accs)
  train_acc2 = 1 - sum(train_acc2) / len(train_acc2)

  print(f"[ Train | {epoch + 1:03d}/{config['num_epoch']:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}, acc2 = {train_acc2:.5f}")
  ### evaluation
  model.eval()

  valid_loss = []
  valid_accs = [] ### match exactly 
  valid_acc2 = [] ### partially correct 

  for batch in tqdm(devLoader):
    inputs, mask, label = batch
    inputs = torch.squeeze(inputs, 1)
    inputs = inputs.to(device)
    mask = mask.to(device)


    with torch.no_grad():
      logits = model(inputs, mask)
    loss = criterion(logits, label.to(device))
    # if flag2 < 5: ### debug
    #   print('flag2 start')
    #   print(logits.argmax(dim=-1))
    #   print(label)
    #   print('flag2 end')
    #   flag2 += 1
    acc = (logits.argmax(dim=-1) == label.to(device)).float().mean()
    acc2 = (abs(logits.argmax(dim=-1) - label.to(device)) / config['num_label']).float().mean()

    valid_loss.append(loss.item())
    valid_accs.append(acc.item())
    valid_acc2.append(acc2.item())

  valid_loss = sum(valid_loss) / len(valid_loss)
  valid_acc = sum(valid_accs) / len(valid_accs)
  valid_acc2 = 1 - sum(valid_acc2) / len(valid_acc2)

  print(f"[ Valid | {epoch + 1:03d}/{config['num_epoch']:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}, acc2 = {valid_acc2:.5f}")

"""### Testing"""

model.eval()

test_loss = []
test_accs = [] ### match exactly 
test_acc2 = [] ### partially correct 

for batch in tqdm(testLoader):
  inputs, mask, label = batch
  inputs = torch.squeeze(inputs, 1)
  inputs = inputs.to(device)
  mask = mask.to(device)

  with torch.no_grad():
    logits = model(inputs, mask)
  loss = criterion(logits, label.to(device))
  acc = (logits.argmax(dim=-1) == label.to(device)).float().mean()
  acc2 = (abs(logits.argmax(dim=-1) - label.to(device)) / config['num_label']).float().mean()

  test_loss.append(loss.item())
  test_accs.append(acc.item())
  test_acc2.append(acc2.item())

test_loss = sum(test_loss) / len(test_loss)
test_acc = sum(test_accs) / len(test_accs)
test_acc2 = 1 - sum(test_acc2) / len(test_acc2)

print(f"[ Test | {epoch + 1:03d}/{config['num_epoch']:03d} ] loss = {test_loss:.5f}, acc = {test_acc:.5f}, acc2 = {test_acc2:.5f}")